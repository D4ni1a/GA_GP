{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "X2HWDLWBNMCw",
   "metadata": {
    "id": "X2HWDLWBNMCw"
   },
   "source": [
    "# Genetic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a5deba",
   "metadata": {
    "id": "b7a5deba"
   },
   "source": [
    "### Idea of the algorithms\n",
    "#### Template 1: Using text embedding with the BERT Transformer:\n",
    "\n",
    "1. Select text columns from the dataframe, encode them with the BERT model;\n",
    "2. Imputing NaN values, if any;\n",
    "3. Dimensionality reduction with PCA;\n",
    "4. Using TPOT to find the most appropriate classification algorithm.\n",
    "\n",
    "#### Template 2: Using tokenization and text embedding with the Spacy model:\n",
    "\n",
    "1. Select text columns from the dataframe and tokenize them;\n",
    "2. Removing punctuation signs and stop words from tokens;\n",
    "3. Using lemmatization to simplify a sentence;\n",
    "4. Vectorization of simplified sentences using one of the Spacy models;\n",
    "5. Imputing NaN values, if any;\n",
    "6. Dimensionality reduction with PCA;\n",
    "7. Using TPOT to find the most appropriate classification algorithm.\n",
    "\n",
    "---\n",
    "\n",
    "Unfortunately, I could not put both algorithms in TPOT due to the high resource limitation. Therefore, I ran both algorithms separately and then compared them on balanced accuracy on a test dataset to determine the best pipeline. In addition, for the reason of the resource limitation, I could not set a large number of generations and individuals within TPOT, so the accuracy value is not very high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fdbcfc",
   "metadata": {},
   "source": [
    "### Step 1: Importing packages and loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xO0N7BTBzMch",
   "metadata": {
    "id": "xO0N7BTBzMch"
   },
   "outputs": [],
   "source": [
    "# # Some extra packages should be installed\n",
    "\n",
    "# !pip install sentence_transformers\n",
    "# !pip install tpot\n",
    "# !pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111a351",
   "metadata": {
    "id": "c111a351"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import spacy\n",
    "import warnings\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tpot import TPOTClassifier\n",
    "from tpot.config import classifier_config_dict_light\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3addd3f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "3addd3f1",
    "outputId": "df380beb-c51d-4f82-8788-4cccd322f237"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9b3aaa0f-fda4-4fc1-b389-5e14957669a8\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>bot?</th>\n",
       "      <th>number_likes</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>False</td>\n",
       "      <td>30634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>False</td>\n",
       "      <td>64192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>False</td>\n",
       "      <td>1396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>False</td>\n",
       "      <td>24049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>False</td>\n",
       "      <td>13076</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>1995</td>\n",
       "      <td>3969</td>\n",
       "      <td>3970</td>\n",
       "      <td>I am visiting Sri Lanka soonfor 9 days, how ca...</td>\n",
       "      <td>Do Indians hate Sri Lankans?</td>\n",
       "      <td>False</td>\n",
       "      <td>24454</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>1996</td>\n",
       "      <td>3971</td>\n",
       "      <td>3972</td>\n",
       "      <td>What are some good examples of 4 stanza poems?</td>\n",
       "      <td>What are some good Ilocano poems?</td>\n",
       "      <td>False</td>\n",
       "      <td>2611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>1997</td>\n",
       "      <td>3973</td>\n",
       "      <td>3974</td>\n",
       "      <td>Which CPU is better I3 4th Gen or 6th Gen?</td>\n",
       "      <td>Which is better intel i5 (6th gen) or i7 (5th ...</td>\n",
       "      <td>True</td>\n",
       "      <td>18483</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>1998</td>\n",
       "      <td>3975</td>\n",
       "      <td>3976</td>\n",
       "      <td>What are some of the best tourist places to vi...</td>\n",
       "      <td>Where are the foremost tourist places in Chhat...</td>\n",
       "      <td>True</td>\n",
       "      <td>28018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>1999</td>\n",
       "      <td>3977</td>\n",
       "      <td>3978</td>\n",
       "      <td>What are the differences between a love marria...</td>\n",
       "      <td>Which is better: an arranged marriage or a lov...</td>\n",
       "      <td>False</td>\n",
       "      <td>20559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 9 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b3aaa0f-fda4-4fc1-b389-5e14957669a8')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-9b3aaa0f-fda4-4fc1-b389-5e14957669a8 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-9b3aaa0f-fda4-4fc1-b389-5e14957669a8');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      Unnamed: 0    id  qid1  qid2  \\\n",
       "0              0     0     1     2   \n",
       "1              1     1     3     4   \n",
       "2              2     2     5     6   \n",
       "3              3     3     7     8   \n",
       "4              4     4     9    10   \n",
       "...          ...   ...   ...   ...   \n",
       "1995        1995  1995  3969  3970   \n",
       "1996        1996  1996  3971  3972   \n",
       "1997        1997  1997  3973  3974   \n",
       "1998        1998  1998  3975  3976   \n",
       "1999        1999  1999  3977  3978   \n",
       "\n",
       "                                              question1  \\\n",
       "0     What is the step by step guide to invest in sh...   \n",
       "1     What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2     How can I increase the speed of my internet co...   \n",
       "3     Why am I mentally very lonely? How can I solve...   \n",
       "4     Which one dissolve in water quikly sugar, salt...   \n",
       "...                                                 ...   \n",
       "1995  I am visiting Sri Lanka soonfor 9 days, how ca...   \n",
       "1996     What are some good examples of 4 stanza poems?   \n",
       "1997         Which CPU is better I3 4th Gen or 6th Gen?   \n",
       "1998  What are some of the best tourist places to vi...   \n",
       "1999  What are the differences between a love marria...   \n",
       "\n",
       "                                              question2   bot?  number_likes  \\\n",
       "0     What is the step by step guide to invest in sh...  False         30634   \n",
       "1     What would happen if the Indian government sto...  False         64192   \n",
       "2     How can Internet speed be increased by hacking...  False          1396   \n",
       "3     Find the remainder when [math]23^{24}[/math] i...  False         24049   \n",
       "4               Which fish would survive in salt water?  False         13076   \n",
       "...                                                 ...    ...           ...   \n",
       "1995                       Do Indians hate Sri Lankans?  False         24454   \n",
       "1996                  What are some good Ilocano poems?  False          2611   \n",
       "1997  Which is better intel i5 (6th gen) or i7 (5th ...   True         18483   \n",
       "1998  Where are the foremost tourist places in Chhat...   True         28018   \n",
       "1999  Which is better: an arranged marriage or a lov...  False         20559   \n",
       "\n",
       "      is_duplicate  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "...            ...  \n",
       "1995             0  \n",
       "1996             0  \n",
       "1997             0  \n",
       "1998             1  \n",
       "1999             0  \n",
       "\n",
       "[2000 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing data\n",
    "df = pd.read_csv('GP data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5001bedf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "5001bedf",
    "outputId": "a5e35ab3-ff44-4b1f-d479-ac01c9fa5287"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6f829014-aea7-4e32-a028-d81df686305b\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>bot?</th>\n",
       "      <th>number_likes</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>False</td>\n",
       "      <td>30634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>False</td>\n",
       "      <td>64192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>False</td>\n",
       "      <td>1396</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>False</td>\n",
       "      <td>24049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>False</td>\n",
       "      <td>13076</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>I am visiting Sri Lanka soonfor 9 days, how ca...</td>\n",
       "      <td>Do Indians hate Sri Lankans?</td>\n",
       "      <td>False</td>\n",
       "      <td>24454</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>What are some good examples of 4 stanza poems?</td>\n",
       "      <td>What are some good Ilocano poems?</td>\n",
       "      <td>False</td>\n",
       "      <td>2611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Which CPU is better I3 4th Gen or 6th Gen?</td>\n",
       "      <td>Which is better intel i5 (6th gen) or i7 (5th ...</td>\n",
       "      <td>True</td>\n",
       "      <td>18483</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>What are some of the best tourist places to vi...</td>\n",
       "      <td>Where are the foremost tourist places in Chhat...</td>\n",
       "      <td>True</td>\n",
       "      <td>28018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>What are the differences between a love marria...</td>\n",
       "      <td>Which is better: an arranged marriage or a lov...</td>\n",
       "      <td>False</td>\n",
       "      <td>20559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 5 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f829014-aea7-4e32-a028-d81df686305b')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-6f829014-aea7-4e32-a028-d81df686305b button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-6f829014-aea7-4e32-a028-d81df686305b');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                              question1  \\\n",
       "0     What is the step by step guide to invest in sh...   \n",
       "1     What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2     How can I increase the speed of my internet co...   \n",
       "3     Why am I mentally very lonely? How can I solve...   \n",
       "4     Which one dissolve in water quikly sugar, salt...   \n",
       "...                                                 ...   \n",
       "1995  I am visiting Sri Lanka soonfor 9 days, how ca...   \n",
       "1996     What are some good examples of 4 stanza poems?   \n",
       "1997         Which CPU is better I3 4th Gen or 6th Gen?   \n",
       "1998  What are some of the best tourist places to vi...   \n",
       "1999  What are the differences between a love marria...   \n",
       "\n",
       "                                              question2   bot?  number_likes  \\\n",
       "0     What is the step by step guide to invest in sh...  False         30634   \n",
       "1     What would happen if the Indian government sto...  False         64192   \n",
       "2     How can Internet speed be increased by hacking...  False          1396   \n",
       "3     Find the remainder when [math]23^{24}[/math] i...  False         24049   \n",
       "4               Which fish would survive in salt water?  False         13076   \n",
       "...                                                 ...    ...           ...   \n",
       "1995                       Do Indians hate Sri Lankans?  False         24454   \n",
       "1996                  What are some good Ilocano poems?  False          2611   \n",
       "1997  Which is better intel i5 (6th gen) or i7 (5th ...   True         18483   \n",
       "1998  Where are the foremost tourist places in Chhat...   True         28018   \n",
       "1999  Which is better: an arranged marriage or a lov...  False         20559   \n",
       "\n",
       "      is_duplicate  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "...            ...  \n",
       "1995             0  \n",
       "1996             0  \n",
       "1997             0  \n",
       "1998             1  \n",
       "1999             0  \n",
       "\n",
       "[2000 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping ID columns\n",
    "new_df = df.drop(['id','qid1','qid2', 'Unnamed: 0'], axis=1)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "651a78e2",
   "metadata": {
    "id": "651a78e2"
   },
   "outputs": [],
   "source": [
    "# Separating data into targets and features\n",
    "y = new_df['is_duplicate']\n",
    "X = new_df.drop(['is_duplicate'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e339d1de",
   "metadata": {},
   "source": [
    "### Step 2: BERT transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17ae19b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480,
     "referenced_widgets": [
      "ffd4160a9cb64c5a84949f3bd7612459",
      "d38583d8c07b4375972f915059f4ec51",
      "42e982fc12f141febaa92885f8be6619",
      "282149d4d7c648fd9a0db528187f2248",
      "8cd0d00f305742098cf13e4913058f69",
      "ce655894fe464540b85e98da9f70c0ec",
      "3639e46ee6ab4e78a6baf7ea0ae81135",
      "8bc86cfc80e44da6b0b869f179dac86d",
      "57ea9bbb33cf497084de5e4724e80e4e",
      "fc955539da1c423fba3de7a4423bf464",
      "77b8641d9f5440b2b987e42af577951e"
     ]
    },
    "id": "c17ae19b",
    "outputId": "2f9a4be4-e608-4891-9ebd-0bc779737b9a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd4160a9cb64c5a84949f3bd7612459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/96 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.6962499999999999\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.6962499999999999\n",
      "\n",
      "Generation 3 - Current best internal CV score: 0.6962499999999999\n",
      "\n",
      "Generation 4 - Current best internal CV score: 0.6987500000000001\n",
      "\n",
      "Generation 5 - Current best internal CV score: 0.6987500000000001\n",
      "\n",
      "Best pipeline: GaussianNB(Normalizer(VarianceThreshold(PCA(StandardScaler(SimpleImputer(BertTransformer(input_matrix))), iterated_power=3, svd_solver=randomized), threshold=0.1), norm=l1))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TPOTClassifier(config_dict={&#x27;__main__.BertTransformer&#x27;: {},\n",
       "                            &#x27;sklearn.cluster.FeatureAgglomeration&#x27;: {&#x27;affinity&#x27;: [&#x27;euclidean&#x27;,\n",
       "                                                                                  &#x27;l1&#x27;,\n",
       "                                                                                  &#x27;l2&#x27;,\n",
       "                                                                                  &#x27;manhattan&#x27;,\n",
       "                                                                                  &#x27;cosine&#x27;],\n",
       "                                                                     &#x27;linkage&#x27;: [&#x27;ward&#x27;,\n",
       "                                                                                 &#x27;complete&#x27;,\n",
       "                                                                                 &#x27;average&#x27;]},\n",
       "                            &#x27;sklearn.decomposition.PCA&#x27;: {&#x27;iterated_power&#x27;: range(1, 11),\n",
       "                                                          &#x27;svd_solver&#x27;: [&#x27;randomized&#x27;]},\n",
       "                            &#x27;sklearn.feature_selection.SelectFwe&#x27;: {&#x27;alpha&#x27;: array([0.   , 0.001, 0.002...\n",
       "                            &#x27;sklearn.preprocessing.StandardScaler&#x27;: {},\n",
       "                            &#x27;sklearn.tree.DecisionTreeClassifier&#x27;: {&#x27;criterion&#x27;: [&#x27;gini&#x27;,\n",
       "                                                                                  &#x27;entropy&#x27;],\n",
       "                                                                    &#x27;max_depth&#x27;: range(1, 11),\n",
       "                                                                    &#x27;min_samples_leaf&#x27;: range(1, 21),\n",
       "                                                                    &#x27;min_samples_split&#x27;: range(2, 21)},\n",
       "                            &#x27;tpot.builtins.ZeroCount&#x27;: {}},\n",
       "               generations=5, population_size=16,\n",
       "               template=&#x27;BertTransformer-SimpleImputer-StandardScaler-PCA-Selector-Transformer-Classifier&#x27;,\n",
       "               verbosity=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TPOTClassifier</label><div class=\"sk-toggleable__content\"><pre>TPOTClassifier(config_dict={&#x27;__main__.BertTransformer&#x27;: {},\n",
       "                            &#x27;sklearn.cluster.FeatureAgglomeration&#x27;: {&#x27;affinity&#x27;: [&#x27;euclidean&#x27;,\n",
       "                                                                                  &#x27;l1&#x27;,\n",
       "                                                                                  &#x27;l2&#x27;,\n",
       "                                                                                  &#x27;manhattan&#x27;,\n",
       "                                                                                  &#x27;cosine&#x27;],\n",
       "                                                                     &#x27;linkage&#x27;: [&#x27;ward&#x27;,\n",
       "                                                                                 &#x27;complete&#x27;,\n",
       "                                                                                 &#x27;average&#x27;]},\n",
       "                            &#x27;sklearn.decomposition.PCA&#x27;: {&#x27;iterated_power&#x27;: range(1, 11),\n",
       "                                                          &#x27;svd_solver&#x27;: [&#x27;randomized&#x27;]},\n",
       "                            &#x27;sklearn.feature_selection.SelectFwe&#x27;: {&#x27;alpha&#x27;: array([0.   , 0.001, 0.002...\n",
       "                            &#x27;sklearn.preprocessing.StandardScaler&#x27;: {},\n",
       "                            &#x27;sklearn.tree.DecisionTreeClassifier&#x27;: {&#x27;criterion&#x27;: [&#x27;gini&#x27;,\n",
       "                                                                                  &#x27;entropy&#x27;],\n",
       "                                                                    &#x27;max_depth&#x27;: range(1, 11),\n",
       "                                                                    &#x27;min_samples_leaf&#x27;: range(1, 21),\n",
       "                                                                    &#x27;min_samples_split&#x27;: range(2, 21)},\n",
       "                            &#x27;tpot.builtins.ZeroCount&#x27;: {}},\n",
       "               generations=5, population_size=16,\n",
       "               template=&#x27;BertTransformer-SimpleImputer-StandardScaler-PCA-Selector-Transformer-Classifier&#x27;,\n",
       "               verbosity=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TPOTClassifier(config_dict={'__main__.BertTransformer': {},\n",
       "                            'sklearn.cluster.FeatureAgglomeration': {'affinity': ['euclidean',\n",
       "                                                                                  'l1',\n",
       "                                                                                  'l2',\n",
       "                                                                                  'manhattan',\n",
       "                                                                                  'cosine'],\n",
       "                                                                     'linkage': ['ward',\n",
       "                                                                                 'complete',\n",
       "                                                                                 'average']},\n",
       "                            'sklearn.decomposition.PCA': {'iterated_power': range(1, 11),\n",
       "                                                          'svd_solver': ['randomized']},\n",
       "                            'sklearn.feature_selection.SelectFwe': {'alpha': array([0.   , 0.001, 0.002...\n",
       "                            'sklearn.preprocessing.StandardScaler': {},\n",
       "                            'sklearn.tree.DecisionTreeClassifier': {'criterion': ['gini',\n",
       "                                                                                  'entropy'],\n",
       "                                                                    'max_depth': range(1, 11),\n",
       "                                                                    'min_samples_leaf': range(1, 21),\n",
       "                                                                    'min_samples_split': range(2, 21)},\n",
       "                            'tpot.builtins.ZeroCount': {}},\n",
       "               generations=5, population_size=16,\n",
       "               template='BertTransformer-SimpleImputer-StandardScaler-PCA-Selector-Transformer-Classifier',\n",
       "               verbosity=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BertTransformer(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"\n",
    "    Transformation algorithm\n",
    "    \n",
    "    Transformation is performed by the BERT model\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializer of the class\n",
    "        \n",
    "        Contains a preloaded BERT model\n",
    "        \"\"\"\n",
    "        # Preloaded BERT model\n",
    "        self.sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Model is already fitted\n",
    "\n",
    "        :param X: pandas dataframe of features\n",
    "        :param y: pandas dataframe of targets\n",
    "        :return: current instance of the transformer class\n",
    "        \"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Embedding of text columns by BERT\n",
    "\n",
    "        :param X: pandas dataframe to be transformed\n",
    "        :return: transformed pandas dataframe\n",
    "        \"\"\"\n",
    "        X_copy = X.copy()\n",
    "        new_data = pd.DataFrame()\n",
    "        for i, column in enumerate(X_copy.columns):\n",
    "            if type(X_copy[column].iloc[0])==str:\n",
    "                # Extracting text features from the dataframe, \n",
    "                # encoding them by BERT encoder\n",
    "                new_column = self.sbert_model.encode(X_copy[column].to_list())\n",
    "                new_column = pd.DataFrame(new_column)\n",
    "\n",
    "                # Store encoded features at new dataframe\n",
    "                for j, col in enumerate(new_column):\n",
    "                    new_data['Feature '+str(i)+\".\"+str(j)] = new_column[col]\n",
    "            else:\n",
    "                # Non-text features should be stored at new dataframe whithout any changes\n",
    "                new_column = X_copy[column]\n",
    "                new_data['Feature '+str(i)] = new_column\n",
    "        return new_data\n",
    "\n",
    "# Splitting data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    train_size=0.8, test_size=0.2, \n",
    "                                                    random_state=123, stratify=np.array(y))\n",
    "\n",
    "# Configuring TPOT classifier with custom BERT feature\n",
    "config_bert = copy.deepcopy(classifier_config_dict_light)\n",
    "config_bert[\"__main__.BertTransformer\"] = {}\n",
    "config_bert['sklearn.impute.SimpleImputer'] = {}\n",
    "config_bert['sklearn.preprocessing.StandardScaler'] = {}\n",
    "\n",
    "# Create and fit TPOT classifier with BERT custom transformer\n",
    "tpot_bert = TPOTClassifier(config_dict=config_bert, verbosity=2, generations=5, population_size=16,\n",
    "                      template='BertTransformer-SimpleImputer-StandardScaler-PCA-Selector-Transformer-Classifier')\n",
    "tpot_bert.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68720a7b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "68720a7b",
    "outputId": "f6871464-c4e9-4250-8a1b-4e5d3e248bc6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6573359073359073"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating balanced accuracy of BERT pipeline on test set\n",
    "y_pred_bert = tpot_bert.predict(X_test)\n",
    "acc_bert = balanced_accuracy_score(y_test, y_pred_bert)\n",
    "acc_bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5240c7",
   "metadata": {},
   "source": [
    "### Step 3: Lemmatizing transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fkYHl0Ed3-cn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341,
     "referenced_widgets": [
      "133af6366b104e878947f911e1df134d",
      "fecd3bbbf10b4b928b52a8aaa4f49b76",
      "d4b98fc613c14c62b4a113062396a672",
      "bdf1eeb1f55144ec8bd249754ec92fa3",
      "4c3553ffedb242d6943da085c44b44b6",
      "d42dfc055d784f8ca5d277d82bfdd0b9",
      "7d2a5bfb21f0424ca9f1aba147490d52",
      "fd8bf1465f1f40dca948b4f9de1f05ba",
      "85040e4f4c74437ea430a897ae137515",
      "bda8179e15294d73850b3b3d6445fc6e",
      "303fb40f92804edf9db107e5c8e43ab9"
     ]
    },
    "id": "fkYHl0Ed3-cn",
    "outputId": "39c0fd34-d39b-47cd-c9da-1ad465a94f17"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133af6366b104e878947f911e1df134d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/32 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.6368750000000001\n",
      "\n",
      "Best pipeline: KNeighborsClassifier(RobustScaler(SelectPercentile(PCA(StandardScaler(SimpleImputer(LemmatizingTransformer(input_matrix))), iterated_power=8, svd_solver=randomized), percentile=15)), n_neighbors=54, p=1, weights=uniform)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TPOTClassifier(config_dict={&#x27;__main__.LemmatizingTransformer&#x27;: {},\n",
       "                            &#x27;sklearn.cluster.FeatureAgglomeration&#x27;: {&#x27;affinity&#x27;: [&#x27;euclidean&#x27;,\n",
       "                                                                                  &#x27;l1&#x27;,\n",
       "                                                                                  &#x27;l2&#x27;,\n",
       "                                                                                  &#x27;manhattan&#x27;,\n",
       "                                                                                  &#x27;cosine&#x27;],\n",
       "                                                                     &#x27;linkage&#x27;: [&#x27;ward&#x27;,\n",
       "                                                                                 &#x27;complete&#x27;,\n",
       "                                                                                 &#x27;average&#x27;]},\n",
       "                            &#x27;sklearn.decomposition.PCA&#x27;: {&#x27;iterated_power&#x27;: range(1, 11),\n",
       "                                                          &#x27;svd_solver&#x27;: [&#x27;randomized&#x27;]},\n",
       "                            &#x27;sklearn.feature_selection.SelectFwe&#x27;: {&#x27;alpha&#x27;: array([0.   , 0.00...\n",
       "                            &#x27;sklearn.preprocessing.StandardScaler&#x27;: {},\n",
       "                            &#x27;sklearn.tree.DecisionTreeClassifier&#x27;: {&#x27;criterion&#x27;: [&#x27;gini&#x27;,\n",
       "                                                                                  &#x27;entropy&#x27;],\n",
       "                                                                    &#x27;max_depth&#x27;: range(1, 11),\n",
       "                                                                    &#x27;min_samples_leaf&#x27;: range(1, 21),\n",
       "                                                                    &#x27;min_samples_split&#x27;: range(2, 21)},\n",
       "                            &#x27;tpot.builtins.ZeroCount&#x27;: {}},\n",
       "               generations=1, population_size=16,\n",
       "               template=&#x27;LemmatizingTransformer-SimpleImputer-StandardScaler-PCA-Selector-Transformer-Classifier&#x27;,\n",
       "               verbosity=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TPOTClassifier</label><div class=\"sk-toggleable__content\"><pre>TPOTClassifier(config_dict={&#x27;__main__.LemmatizingTransformer&#x27;: {},\n",
       "                            &#x27;sklearn.cluster.FeatureAgglomeration&#x27;: {&#x27;affinity&#x27;: [&#x27;euclidean&#x27;,\n",
       "                                                                                  &#x27;l1&#x27;,\n",
       "                                                                                  &#x27;l2&#x27;,\n",
       "                                                                                  &#x27;manhattan&#x27;,\n",
       "                                                                                  &#x27;cosine&#x27;],\n",
       "                                                                     &#x27;linkage&#x27;: [&#x27;ward&#x27;,\n",
       "                                                                                 &#x27;complete&#x27;,\n",
       "                                                                                 &#x27;average&#x27;]},\n",
       "                            &#x27;sklearn.decomposition.PCA&#x27;: {&#x27;iterated_power&#x27;: range(1, 11),\n",
       "                                                          &#x27;svd_solver&#x27;: [&#x27;randomized&#x27;]},\n",
       "                            &#x27;sklearn.feature_selection.SelectFwe&#x27;: {&#x27;alpha&#x27;: array([0.   , 0.00...\n",
       "                            &#x27;sklearn.preprocessing.StandardScaler&#x27;: {},\n",
       "                            &#x27;sklearn.tree.DecisionTreeClassifier&#x27;: {&#x27;criterion&#x27;: [&#x27;gini&#x27;,\n",
       "                                                                                  &#x27;entropy&#x27;],\n",
       "                                                                    &#x27;max_depth&#x27;: range(1, 11),\n",
       "                                                                    &#x27;min_samples_leaf&#x27;: range(1, 21),\n",
       "                                                                    &#x27;min_samples_split&#x27;: range(2, 21)},\n",
       "                            &#x27;tpot.builtins.ZeroCount&#x27;: {}},\n",
       "               generations=1, population_size=16,\n",
       "               template=&#x27;LemmatizingTransformer-SimpleImputer-StandardScaler-PCA-Selector-Transformer-Classifier&#x27;,\n",
       "               verbosity=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TPOTClassifier(config_dict={'__main__.LemmatizingTransformer': {},\n",
       "                            'sklearn.cluster.FeatureAgglomeration': {'affinity': ['euclidean',\n",
       "                                                                                  'l1',\n",
       "                                                                                  'l2',\n",
       "                                                                                  'manhattan',\n",
       "                                                                                  'cosine'],\n",
       "                                                                     'linkage': ['ward',\n",
       "                                                                                 'complete',\n",
       "                                                                                 'average']},\n",
       "                            'sklearn.decomposition.PCA': {'iterated_power': range(1, 11),\n",
       "                                                          'svd_solver': ['randomized']},\n",
       "                            'sklearn.feature_selection.SelectFwe': {'alpha': array([0.   , 0.00...\n",
       "                            'sklearn.preprocessing.StandardScaler': {},\n",
       "                            'sklearn.tree.DecisionTreeClassifier': {'criterion': ['gini',\n",
       "                                                                                  'entropy'],\n",
       "                                                                    'max_depth': range(1, 11),\n",
       "                                                                    'min_samples_leaf': range(1, 21),\n",
       "                                                                    'min_samples_split': range(2, 21)},\n",
       "                            'tpot.builtins.ZeroCount': {}},\n",
       "               generations=1, population_size=16,\n",
       "               template='LemmatizingTransformer-SimpleImputer-StandardScaler-PCA-Selector-Transformer-Classifier',\n",
       "               verbosity=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LemmatizingTransformer(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"\n",
    "    Transformation algorithm\n",
    "    \n",
    "    Transformation is performed by tokenization, lematization, and vectorizing by Spacy model\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializer of the class\n",
    "\n",
    "        Contains a preloaded Spacy model and Lemmatizer\n",
    "        \"\"\"\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Model is already fitted\n",
    "\n",
    "        :param X: pandas dataframe of features\n",
    "        :param y: pandas dataframe of targets\n",
    "        :return: current instance of the transformer class\n",
    "        \"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Embedding of text columns by Spacy\n",
    "\n",
    "        :param X: pandas dataframe to be transformed\n",
    "        :return: transformed pandas dataframe\n",
    "        \"\"\"\n",
    "        X_copy = X.copy()\n",
    "        output_df = pd.DataFrame()\n",
    "        for i, column in enumerate(X_copy.columns):\n",
    "            if type(X_copy[column].iloc[0])==str:\n",
    "                # Extracting text features from the dataframe\n",
    "                vectorized = []\n",
    "                for sentence in X_copy[column]:\n",
    "                    # Tokenization of the sentence\n",
    "                    tokens = sentence.lower()\n",
    "                    tokens = self.nlp(tokens)\n",
    "                    tokenized = \"\"\n",
    "                    for token in tokens:\n",
    "                        if not (token.is_punct or token.is_stop):\n",
    "                            # Removing stop words and punctuation signs from the list of tokens\n",
    "                            tokenized+=str(token.lemma_)\n",
    "                            tokenized+=\" \"\n",
    "\n",
    "                    # Forming a new sentence from non-removed tokens\n",
    "                    tokenized = \" \".join(word_tokenize(tokenized))\n",
    "\n",
    "                    # Lematizing words from the sentence\n",
    "                    lemmatized = []\n",
    "                    for word in tokenized.split():\n",
    "                        lemmatized.append(str(self.lemmatizer.lemmatize(word, pos=\"v\")))\n",
    "                    string = \" \".join(lemmatized)\n",
    "\n",
    "                    # Removing repeating tokens\n",
    "                    words = []\n",
    "                    for j in lemmatized:\n",
    "                        if (string.count(j)>=1 and (j not in words)):\n",
    "                            words.append(j)\n",
    "                    final_sentence = ' '.join(words)\n",
    "\n",
    "                    # Vectorization of the final version of sentence\n",
    "                    final_sentence = self.nlp(final_sentence)\n",
    "                    vectorized.append(list(final_sentence.vector))\n",
    "                    \n",
    "                # Append new features to dataframe\n",
    "                pd_vectorized = pd.DataFrame(vectorized)\n",
    "                pd_vectorized = pd_vectorized.rename(columns={\n",
    "                    x: \"Feature.\"+str(i)+\".\"+str(x) for x in range(len(pd_vectorized.columns))\n",
    "                })\n",
    "                output_df = pd.concat([output_df, pd_vectorized], axis=1)\n",
    "            else:\n",
    "                # For non-text features\n",
    "                output_df[\"Feature \"+str(i)] = pd.DataFrame(X_copy[column])\n",
    "        return output_df\n",
    "\n",
    "# Configuring TPOT classifier with custom lemmatizing features\n",
    "config_lem = copy.deepcopy(classifier_config_dict_light)\n",
    "config_lem[\"__main__.LemmatizingTransformer\"] = {}\n",
    "config_lem['sklearn.impute.SimpleImputer'] = {}\n",
    "config_lem['sklearn.preprocessing.StandardScaler'] = {}\n",
    "\n",
    "# Create and fit TPOT classifier with a custom lemmatizing transformer\n",
    "tpot_lem = TPOTClassifier(config_dict=config_lem, verbosity=2, generations=1, population_size=16,\n",
    "                      template='LemmatizingTransformer-SimpleImputer-StandardScaler-PCA-Selector-Transformer-Classifier')\n",
    "tpot_lem.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "yNj6AaPePpf7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yNj6AaPePpf7",
    "outputId": "3b2be9f4-eb56-4abb-d9a0-4bb3ab016256"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5342127842127842"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating balanced accuracy of lemmatizing pipeline on test set\n",
    "y_pred_lem = tpot_lem.predict(X_test)\n",
    "acc_lem = balanced_accuracy_score(y_test, y_pred_lem)\n",
    "acc_lem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d114ec1e",
   "metadata": {},
   "source": [
    "### Step 4: Pipelines comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ln9MyoLY3rE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ln9MyoLY3rE",
    "outputId": "70caad84-3d5b-442b-bdee-6ac956de4d8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best pipeline: TPOTClassifier(config_dict={'__main__.BertTransformer': {},\n",
      "                            'sklearn.cluster.FeatureAgglomeration': {'affinity': ['euclidean',\n",
      "                                                                                  'l1',\n",
      "                                                                                  'l2',\n",
      "                                                                                  'manhattan',\n",
      "                                                                                  'cosine'],\n",
      "                                                                     'linkage': ['ward',\n",
      "                                                                                 'complete',\n",
      "                                                                                 'average']},\n",
      "                            'sklearn.decomposition.PCA': {'iterated_power': range(1, 11),\n",
      "                                                          'svd_solver': ['randomized']},\n",
      "                            'sklearn.feature_selection.SelectFwe': {'alpha': array([0.   , 0.001, 0.002...\n",
      "                            'sklearn.preprocessing.StandardScaler': {},\n",
      "                            'sklearn.tree.DecisionTreeClassifier': {'criterion': ['gini',\n",
      "                                                                                  'entropy'],\n",
      "                                                                    'max_depth': range(1, 11),\n",
      "                                                                    'min_samples_leaf': range(1, 21),\n",
      "                                                                    'min_samples_split': range(2, 21)},\n",
      "                            'tpot.builtins.ZeroCount': {}},\n",
      "               generations=5, population_size=16,\n",
      "               template='BertTransformer-SimpleImputer-StandardScaler-PCA-Selector-Transformer-Classifier',\n",
      "               verbosity=2)\n",
      "Best balanced accuracy: 0.6573359073359073\n"
     ]
    }
   ],
   "source": [
    "# Choose best pipeline of BERT and Lemmatizing ones\n",
    "if acc_lem > acc_bert:\n",
    "    best_pipe = tpot_lem\n",
    "    best_acc = acc_lem\n",
    "else:\n",
    "    best_pipe = tpot_bert\n",
    "    best_acc = acc_bert\n",
    "\n",
    "best_pipe.export(\"best_pipeline.py\")\n",
    "print(\"Best pipeline:\", best_pipe)\n",
    "print(\"Best balanced accuracy:\", best_acc)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "133af6366b104e878947f911e1df134d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fecd3bbbf10b4b928b52a8aaa4f49b76",
       "IPY_MODEL_d4b98fc613c14c62b4a113062396a672",
       "IPY_MODEL_bdf1eeb1f55144ec8bd249754ec92fa3"
      ],
      "layout": "IPY_MODEL_4c3553ffedb242d6943da085c44b44b6"
     }
    },
    "282149d4d7c648fd9a0db528187f2248": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc955539da1c423fba3de7a4423bf464",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_77b8641d9f5440b2b987e42af577951e",
      "value": " 96/96 [2:20:21&lt;00:00, 79.46s/pipeline]"
     }
    },
    "303fb40f92804edf9db107e5c8e43ab9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3639e46ee6ab4e78a6baf7ea0ae81135": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "42e982fc12f141febaa92885f8be6619": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8bc86cfc80e44da6b0b869f179dac86d",
      "max": 96,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_57ea9bbb33cf497084de5e4724e80e4e",
      "value": 96
     }
    },
    "4c3553ffedb242d6943da085c44b44b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "57ea9bbb33cf497084de5e4724e80e4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "77b8641d9f5440b2b987e42af577951e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d2a5bfb21f0424ca9f1aba147490d52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "85040e4f4c74437ea430a897ae137515": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8bc86cfc80e44da6b0b869f179dac86d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cd0d00f305742098cf13e4913058f69": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "bda8179e15294d73850b3b3d6445fc6e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdf1eeb1f55144ec8bd249754ec92fa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bda8179e15294d73850b3b3d6445fc6e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_303fb40f92804edf9db107e5c8e43ab9",
      "value": " 32/32 [1:51:30&lt;00:00, 204.54s/pipeline]"
     }
    },
    "ce655894fe464540b85e98da9f70c0ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d38583d8c07b4375972f915059f4ec51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce655894fe464540b85e98da9f70c0ec",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_3639e46ee6ab4e78a6baf7ea0ae81135",
      "value": "Optimization Progress: 100%"
     }
    },
    "d42dfc055d784f8ca5d277d82bfdd0b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4b98fc613c14c62b4a113062396a672": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd8bf1465f1f40dca948b4f9de1f05ba",
      "max": 32,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_85040e4f4c74437ea430a897ae137515",
      "value": 32
     }
    },
    "fc955539da1c423fba3de7a4423bf464": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd8bf1465f1f40dca948b4f9de1f05ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fecd3bbbf10b4b928b52a8aaa4f49b76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d42dfc055d784f8ca5d277d82bfdd0b9",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7d2a5bfb21f0424ca9f1aba147490d52",
      "value": "Optimization Progress: 100%"
     }
    },
    "ffd4160a9cb64c5a84949f3bd7612459": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d38583d8c07b4375972f915059f4ec51",
       "IPY_MODEL_42e982fc12f141febaa92885f8be6619",
       "IPY_MODEL_282149d4d7c648fd9a0db528187f2248"
      ],
      "layout": "IPY_MODEL_8cd0d00f305742098cf13e4913058f69"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
